{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59a9ab-b48d-4d21-af35-41f34b542ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn.linear_model, sklearn.neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b2681-5e13-4eb4-937f-b03c5a05e399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_country_stats(oecd_bli, gdp_per_capita):\n",
    "    oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
    "    oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
    "    gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"}, inplace=True)\n",
    "    gdp_per_capita.set_index(\"Country\", inplace=True)\n",
    "    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n",
    "                                  left_index=True, right_index=True)\n",
    "    full_country_stats.sort_values(by=\"GDP per capita\", inplace=True)\n",
    "    remove_indices = [0, 1, 6, 8, 33, 34, 35]\n",
    "    keep_indices = list(set(range(36)) - set(remove_indices))\n",
    "    return full_country_stats[[\"GDP per capita\", 'Life satisfaction']].iloc[keep_indices]\n",
    "\n",
    "\n",
    "oecd_bli = pd.read_csv('datasets/oecd_bli_2015.csv', thousands = ',')\n",
    "gdp_per_capita = pd.read_csv('datasets/gdp_per_capita.csv', thousands = ',', delimiter = '\\t', encoding = 'latin1', na_values = 'n/a')\n",
    "country_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\n",
    "X, y = np.c_[country_stats['GDP per capita']], np.c_[country_stats['Life satisfaction']] #vectorize\n",
    "country_stats.plot(kind = 'scatter', x='GDP per capita', y='Life satisfaction')\n",
    "model_linear = sklearn.linear_model.LinearRegression()\n",
    "model_linear.fit(X, y)\n",
    "model_k_nearest = sklearn.neighbors.KNeighborsRegressor(n_neighbors = 3)\n",
    "model_k_nearest.fit(X, y)\n",
    "X_new = [[22587]]\n",
    "print(model_k_nearest.predict(X_new))\n",
    "print(model_linear.predict(X_new))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06b86b-8a46-49e5-ba6d-5657aba11e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798f8b95-7e70-431a-82db-ae3eb5b76f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc4090-1582-4680-92f9-711980c0e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "download_root = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "housing_path = os.path.join(\"datasets\", \"housing\")\n",
    "housing_url = download_root + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def get_housing_data(housing_url, housing_path):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, 'housing.tgz')\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "\n",
    "def load_housing_data(housing_path):\n",
    "    csv_path = os.path.join(housing_path, 'housing.csv')\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['income_cat'] = pd.cut(df['median_income'], bins=[0., 1.5, 3.0, 4.5, 6., np.inf], labels=[1, 2, 3, 4, 5])\n",
    "    # df['income_cat'].hist()  # classify incomes into bins\n",
    "    # plt.show()\n",
    "    return df\n",
    "\n",
    "\n",
    "get_housing_data(housing_url, housing_path)\n",
    "df = load_housing_data(housing_path)\n",
    "\n",
    "train_set, test_set = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\n",
    "#ensures both sets would have approximately the  same percentages for each income category as the original dataset\n",
    "for train_index, test_index in split.split(df, df['income_cat']):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]\n",
    "\n",
    "#drop dummy strat var\n",
    "strat_test_set['income_cat'].value_counts() / len(strat_test_set)\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis = 1, inplace = True)\n",
    "\n",
    "housing = strat_test_set.copy()\n",
    "# housing.plot(kind = 'scatter', x = 'longitude', y = 'latitude', alpha = 0.1)\n",
    "# housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "#         s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
    "#         c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
    "#     )\n",
    "# plt.legend()\n",
    "numeric_columns = housing.select_dtypes(include=[np.number]).columns\n",
    "corr_matrix = housing[numeric_columns].corr()\n",
    "corr_matrix['median_house_value'].sort_values(ascending=False)\n",
    "\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
    "                  \"housing_median_age\"]\n",
    "# scatter_matrix(housing[attributes], figsize=(12, 8))\n",
    "housing.plot(kind = 'scatter', x = 'median_income', y = 'median_house_value', alpha = 0.1)\n",
    "\n",
    "housing['rooms_per_household'] = housing['total_rooms'] / housing['households']\n",
    "housing['bedrooms_per_room'] = housing['total_bedrooms'] / housing['total_rooms']\n",
    "housing['population_per_household'] = housing['population'] / housing['households']\n",
    "\n",
    "numeric_columns = housing.select_dtypes(include=[np.number]).columns\n",
    "corr_matrix = housing[numeric_columns].corr()\n",
    "corr_matrix['median_house_value'].sort_values(ascending = False)\n",
    "\n",
    "housing = strat_train_set.drop('median_house_value', axis = 1)\n",
    "housing_labels = strat_train_set['median_house_value'].copy()\n",
    "\n",
    "#missing vals with median\n",
    "# housing['total_bedrooms'].fillna(0)\n",
    "imputer = SimpleImputer(strategy = 'median')\n",
    "housing_num = housing.drop('ocean_proximity', axis = 1)\n",
    "imputer.fit(housing_num)\n",
    "imputer.statistics_\n",
    "housing_num.median().values\n",
    "X = imputer.transform(housing_num)\n",
    "housing_tr = pd.DataFrame(X, columns = housing_num.columns, index = housing_num.index)\n",
    "\n",
    "#one hot encode the labels for the ocean_proximity feature\n",
    "housing_cat = housing[['ocean_proximity']]\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a3c1d-219b-4ec1-bdd6-a020c0fbf257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling \n",
    "min_max_scaler = MinMaxScaler(feature_range = (-1, 1))\n",
    "housing_num_min_max_scaled = min_max_scaler.fit_transform(housing_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5547537-76a1-4c36-ad10-578f4cfcbfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y = None):\n",
    "        return self \n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809ec6d4-ebd3-4b86-9deb-87c913680704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy = 'median')), \n",
    "        ('attribs_adder', CombinedAttributesAdder()), \n",
    "        ('std_scaler', StandardScaler()),\n",
    "])\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_tr)\n",
    "housing_num_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f6a67f-182d-4176-960f-77a7a4cc49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = ['ocean_proximity']\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attribs), \n",
    "    ('cat', OneHotEncoder(), cat_attribs),\n",
    "\n",
    "])\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af7d55-6fad-47fb-878b-7f77cba24267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c7cc4-ce56-4858-9173-6d97a8e5ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels\", list(some_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cdd56b-e7fa-49e2-b134-671373bfaf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse #in dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da745bc-4f6b-47fd-b3f9-8437624c5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor \n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e099c751-ff9a-4e48-8dfa-44b8e994a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
    "                         scoring = 'neg_mean_squared_error', cv = 10)\n",
    "\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"STD:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f27e32-37bc-40e1-92fd-6e6a92e189a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
    "                         scoring = 'neg_mean_squared_error', cv = 10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f0756-d2a9-4a70-9534-1097906428f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(housing_prepared, housing_labels)\n",
    "\n",
    "housing_predictions = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "\n",
    "scores = cross_val_score(forest_reg, housing_prepared, housing_labels,\n",
    "                         scoring = 'neg_mean_squared_error', cv = 10)\n",
    "\n",
    "forest_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a303f6-29b1-43bd-99ef-7e1ee7373488",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(lin_reg, 'lin_reg_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a4682-67a3-4ac1-a13b-2fe5a73eba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = joblib.load('lin_reg_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e57ca-cf1a-46f6-889c-c54b5bae3d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV #good for relatively few combinations\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]}, \n",
    "    {'bootstrap': [False], 'n_estimators':[3, 10], 'max_features':[2, 3, 4]},\n",
    "]\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "#12 combinations of n_estimators and max_features, \n",
    "#6 combinations of hyperparams in second dict\n",
    "#18 conbinations altogether, will train each model 5 times (five 5 cross val)\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv = 5,  \n",
    "                           scoring = 'neg_mean_squared_error', \n",
    "                           return_train_score = True)\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12446be6-ad9a-4b14-9a37-c86c0c2d5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# param_distributions = [\n",
    "#     {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]}, \n",
    "#     {'bootstrap': [False], 'n_estimators':[3, 10], 'max_features':[2, 3, 4]},\n",
    "# ]\n",
    "# forest_reg = RandomForestRegressor()\n",
    "\n",
    "# #12 combinations of n_estimators and max_features, \n",
    "# #6 combinations of hyperparams in second dict\n",
    "# #18 conbinations altogether, will train each model 5 times (five 5 cross val)\n",
    "# grid_search = RandomizedSearchCV(forest_reg, param_distributions, cv = 5,  \n",
    "#                            scoring = 'neg_mean_squared_error', \n",
    "#                            return_train_score = True)\n",
    "# grid_search.fit(housing_prepared, housing_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcec89d-1324-47e3-b17d-1e81dbc86277",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686574cc-fa68-4a41-8958-ac8cedfa66b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe2695e-5382-40e5-9317-a9542d75abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf98a59-6515-49ed-82de-121906850332",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497cd76d-d910-4409-a05a-f44f7dd61e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_attribs = ['rooms_per_hhold', 'pop_per_hhold', 'bedrooms_per_room']\n",
    "cat_encoder = full_pipeline.named_transformers_['cat']\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs \n",
    "sorted(zip(feature_importances, attributes), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b328e-aac7-4f97-b61e-bea3f41bf58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa308b12-8164-4dda-8667-0e5d1a67355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop('median_house_value', axis = 1)\n",
    "y_test = strat_test_set['median_house_value'].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda5724-9a8d-4e02-9f5c-1cda263c5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats \n",
    "confidence = 0.95 \n",
    "\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1, \n",
    "                          loc = squared_errors.mean(), \n",
    "                          scale = stats.sem(squared_errors)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
